{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1\n",
    "## Team Members -\n",
    "### Shrenik Ganguli : CS23MTECH14014\n",
    "### Trishita Saha      : CS23MTECH14016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR-2bbG5pd-j"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hz6ty95jhMW6"
   },
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import string\n",
    "import math\n",
    "\n",
    "#Function for text preprocessing\n",
    "def text_pre_processing(text):\n",
    "    text = text.lower() #Converts text into lower case\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')  #Remove punctuation\n",
    "    return text.split() #Split the text into words and return list\n",
    "\n",
    "#Function for modified n-gram precision\n",
    "def modified_ngram_precision(x, y, n):\n",
    "    \"\"\"\n",
    "    Calculates the modified n-gram precision between two lists of words.\n",
    "    Parameters:\n",
    "    - x: List of words (reference)\n",
    "    - y: List of words (candidate)\n",
    "    - n: Size of n-gram\n",
    "    Returns:\n",
    "    - Modified n-gram precision\n",
    "    \"\"\"\n",
    "    x_ngrams = []\n",
    "    y_ngrams = []\n",
    "\n",
    "    # Generate n-grams for both lists\n",
    "    for i in range(len(x) - n + 1):\n",
    "        x_ngrams.append(x[i:i + n])\n",
    "    for j in range(len(y) - n + 1):\n",
    "        y_ngrams.append(y[j:j + n])\n",
    "\n",
    "    # Convert n-grams to tuples for comparison\n",
    "    x_ngrams = [tuple(ngram) for ngram in x_ngrams]\n",
    "    y_ngrams = [tuple(ngram) for ngram in y_ngrams]\n",
    "\n",
    "    # Get unique n-grams from reference list\n",
    "    unique_x_ngrams = list(set(x_ngrams))\n",
    "\n",
    "    # Calculate the modified n-gram precision\n",
    "    min_grams = 0\n",
    "    for ngram in unique_x_ngrams:\n",
    "        if ngram in y_ngrams:\n",
    "            min_grams += min(x_ngrams.count(ngram), y_ngrams.count(ngram))\n",
    "    count_x_ngrams = len(x_ngrams)\n",
    "    return min_grams / count_x_ngrams\n",
    "\n",
    "\n",
    "#Function for BLEU score calculation\n",
    "def bleu_score(x, y, N=4, BP=1):\n",
    "    \"\"\"\n",
    "    Calculates the BLEU score between two lists of words.\n",
    "\n",
    "    Parameters:\n",
    "    - x: List of words (reference)\n",
    "    - y: List of words (candidate)\n",
    "    - N: Maximum n-gram size (default = 4)\n",
    "    - BP: Brevity penalty (default = 1)\n",
    "\n",
    "    Returns:\n",
    "    - BLEU score\n",
    "    \"\"\"\n",
    "    w = [1 / N] * N\n",
    "    b = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        p = modified_ngram_precision(x, y, (i + 1))\n",
    "\n",
    "        # Handle cases where p is zero\n",
    "        if p == 0:\n",
    "\n",
    "            #p = 1e-10  # A small epsilon value\n",
    "\n",
    "            b = -1\n",
    "            break # Since no common n-gram found BLEU score = 0\n",
    "\n",
    "            #continue # Since if p=0 we assume log(p)=0\n",
    "\n",
    "        b += w[i] * math.log(p)\n",
    "\n",
    "    b = math.exp(b) if b != -1 else 0\n",
    "    b = BP * b\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsWDO50appzE"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRNx9eISpnIr",
    "outputId": "cb18985b-f81b-404d-ae56-df6d6a06638a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLUE score for x = 'The boys were playing happily on the ground.' and y = 'The boys were playing football on the field.' is: 0.4111336169005197\n"
     ]
    }
   ],
   "source": [
    "#Implementation of BLUE score\n",
    "x = \"The boys were playing happily on the ground.\"\n",
    "y = \"The boys were playing football on the field.\"\n",
    "print(f\"The BLUE score for x = '{x}' and y = '{y}' is:\", end=\" \")\n",
    "\n",
    "x = text_pre_processing(x)\n",
    "y = text_pre_processing(y)\n",
    "\n",
    "BLEU = bleu_score(x,y)\n",
    "print(BLEU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oqBA3pVpzOS"
   },
   "source": [
    "## Question 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> The minimum in the numerator prevents overestimation of n-gram matches by ensuring that the count of an n-gram in the intersection is not higher than its count in the reference sentence. This maintains a balanced comparison between the candidate and reference sentences for accurate evaluation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4eU_RkRqfYK"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXIIbNHKhz9L",
    "outputId": "4aadf619-5dbf-4832-a741-2d8889b55e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLEU score for sentence pair 1:\n",
      "x = 'I want to do research in NLP.'\n",
      "y = 'NLP is my research area.'\n",
      "BLEU Score: 0\n",
      "\n",
      "The BLEU score for sentence pair 2:\n",
      "x = 'The quick brown fox jumps over the lazy dog all day long.'\n",
      "y = 'The fast brown fox jumps over the sleepy dog.'\n",
      "BLEU Score: 0.3448444257953326\n",
      "\n",
      "The BLEU score for sentence pair 3:\n",
      "x = 'A.R Rahman is a musical legend'\n",
      "y = 'A.R Rahman is a legendary musician'\n",
      "BLEU Score: 0.5081327481546147\n",
      "\n",
      "The BLEU score for sentence pair 4:\n",
      "x = 'The man arrived late because of the train'\n",
      "y = 'The train arrived late because of the man'\n",
      "BLEU Score: 0.6434588841607617\n",
      "\n",
      "The BLEU score for sentence pair 5:\n",
      "x = 'I love IIT Hyderabad.'\n",
      "y = 'Everyone loves IIT Hyderabad.'\n",
      "BLEU Score: 0\n",
      "\n",
      "\n",
      "\u001b[1mPotential disadvantages of BLEU Score:\u001b[0m\n",
      "i)  Sensitivity to sentence length (as seen in example 2)\n",
      "ii) Emphasis on n-gram precision over semantic meaning (as seen in example 1)\n",
      "iii)BLEU does not understand the variants of the words and can’t take the word order into account. (as seen in \n",
      "    example 3 & 4)\n",
      "iv) Limited applicability across languages with diverse word orders or morphologies\n",
      "v)  BLEU does not understand the significance of the words in the text, and penalizes relatively less important \n",
      "    words as much as words more important to the statement. This is problem is more significant in smaller sentence \n",
      "    due to brevity penalty formula.\n"
     ]
    }
   ],
   "source": [
    "#Example sentences\n",
    "sentence_pairs = [\n",
    "    (\"I want to do research in NLP.\", \"NLP is my research area.\"),\n",
    "    (\"The quick brown fox jumps over the lazy dog all day long.\", \"The fast brown fox jumps over the sleepy dog.\"),\n",
    "    (\"A.R Rahman is a musical legend\", \"A.R Rahman is a legendary musician\"),\n",
    "    (\"The man arrived late because of the train\", \"The train arrived late because of the man\"),\n",
    "    (\"I love IIT Hyderabad.\", \"Everyone loves IIT Hyderabad.\"),\n",
    "]\n",
    "\n",
    "for index, pair in enumerate(sentence_pairs, start=1):\n",
    "    x = pair[0]\n",
    "    y = pair[1]\n",
    "    # Calculate and print BLEU score\n",
    "    print(f\"The BLEU score for sentence pair {index}:\")\n",
    "    print(f\"x = '{x}'\")\n",
    "    print(f\"y = '{y}'\")\n",
    "    x = text_pre_processing(x)\n",
    "    y = text_pre_processing(y)\n",
    "\n",
    "\n",
    "    BLEU = bleu_score(x, y)\n",
    "    print(f\"BLEU Score: {BLEU}\\n\")\n",
    "\n",
    "\n",
    "# Potential disadvantages of BLEU Score:\n",
    "print(\"\\n\"+'\\033[1m'+\"Potential disadvantages of BLEU Score:\"+'\\033[0m')\n",
    "print(\"i)  Sensitivity to sentence length (as seen in example 2)\")\n",
    "print(\"ii) Emphasis on n-gram precision over semantic meaning (as seen in example 1)\")\n",
    "print(\"iii)BLEU does not understand the variants of the words and can’t take the word order into account. (as seen in \")\n",
    "print(\"    example 3 & 4)\")\n",
    "print(\"iv) Limited applicability across languages with diverse word orders or morphologies\")\n",
    "print(\"v)  BLEU does not understand the significance of the words in the text, and penalizes relatively less important \")\n",
    "print(\"    words as much as words more important to the statement. This is problem is more significant in smaller sentence \")\n",
    "print(\"    due to brevity penalty formula.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
